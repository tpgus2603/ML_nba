# -*- coding: utf-8 -*-
"""웹크롤링하기.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PnQIWzizIz1trC4wCj3TS0y56e0_dM7D
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd


existing_data_path = '/mnt/data/path_to_existing_data (1).csv'

# Attempt to reload the existing dataset
try:
    existing_data = pd.read_csv(existing_data_path)
    print("Existing data loaded successfully.")
    print(existing_data.head())
except Exception as e:
    print("An error occurred while loading the existing data:", str(e))

# Function to scrape player data from Spotrac
def scrape_spotrac_team(team_url):
    response = requests.get(team_url)
    soup = BeautifulSoup(response.text, 'html.parser')
    players = []

    # Locate the table with player contracts
    table = soup.find('table', class_='datatable')
    if not table:
        return players

    # Extract data from the table rows
    rows = table.find_all('tr')[1:]  # Skip header row
    for row in rows:  # Limit to 10 players per team
        cols = row.find_all('td')
        if len(cols) < 8:
            continue
        player_name = cols[0].text.strip()
        contract_year = cols[1].text.strip()
        annual_salary = cols[2].text.strip().replace('$', '').replace(',', '')
        birth_year = cols[4].text.strip()
        team_abbr = team_url.split('/')[-2].upper()

        players.append({
            'Player': player_name,
            'Contract Year': int(contract_year),
            'Annual Salary': int(annual_salary),
            'Team': team_abbr,
            'Birth Year': int(birth_year),
            'Age': int(cols[5].text.strip())
        })
    return players

# URLs for the Spotrac pages of the teams
team_urls = {
    'LAL': 'https://www.spotrac.com/nba/los-angeles-lakers/',
    'ORL': 'https://www.spotrac.com/nba/orlando-magic/',
    'PHI': 'https://www.spotrac.com/nba/philadelphia-76ers/',
    'TOR': 'https://www.spotrac.com/nba/toronto-raptors/',
    'DEN': 'https://www.spotrac.com/nba/denver-nuggets/',
    'UTA': 'https://www.spotrac.com/nba/utah-jazz/'
}

# Scrape data for all teams
all_players_data = []
for team, url in team_urls.items():
    team_players = scrape_spotrac_team(url)
    all_players_data.extend(team_players)

# Convert the scraped data to a DataFrame
scraped_df = pd.DataFrame(all_players_data)
scraped_df.head()

# Load the existing data
existing_data_path = 'path_to_existing_data.csv'
existing_data = pd.read_csv(existing_data_path)

# Append the new data to the existing dataframe
updated_nba_data = pd.concat([existing_data, scraped_df], ignore_index=True)

# Remove duplicate rows from the updated dataframe
cleaned_nba_data = updated_nba_data.drop_duplicates()

# Save the cleaned dataframe to a new CSV file
cleaned_file_path = 'cleaned_nba_player_data.csv'
cleaned_nba_data.to_csv(cleaned_file_path, index=False)